# AnnoSUM-MI


### This repository contains the AnnoSUM-MI Dataset, Summaries of Motivational Interviewing (MI) generated by the Large Language Models (LLMs), Prompts, and Results, and it is structured as follows:



### Dataset
This folder contains the following files:

* `train_dataset_MI_sessions.csv`: This file contains the original MI dialogues of the training dataset.
* `test_dataset._MI_sessions.csv`: This file contains the original MI dialogues of the training dataset.
* `train_data_MI_annotated.csv`: This file contains the annotated MI dialogues across six components of MITI.
* `test_data_MI_annotated.csv`: This file contains the annotated MI dialogues across six components of MITI.
* `chatgpt_summaries.csv`: This file contains the summaries generated by ChatGPT and the corresponding expert annotation across six components of MITI. 
* `Gemini_summaries.csv`: This file contains the summaries generated by Gemini and the corresponding expert annotation across six components of MITI.
* `DeepSeek_summaries.csv`: This file contains the summaries generated by DeepSeek and the corresponding expert annotation across six components of MITI.

### Models
The LLMs used for the experiments : 
```
OpenAIChatGPT (Version: )
DeepSeek (Version: )
Google Gemini (Version: )
```

### Supplementary Material
* `Prompts`: This file contains the original MI dialogues of the training dataset.
* 
  

### Publication (International Joint Conference on Neural Networks, 2025, Rome, Italy)
### Mitigating Semantic Drift: Evaluating LLMs' Efficacy in Psychotherapy through MI Dialogue Summarization Leveraging MITI Code

Cite as :

```

## Acknowledgements
This work has been funded by the EC in the H2020 Marie Sk≈Çodowska-Curie PhilHumans project (contract no. 812882) and the European Research Council (Grant agreement No. 101039303 NG-NLG).
<figure src="img/LOGO_ERC-FLAG_FP.png" alt="erc-logo" height="150"/> 



















